{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "442bd296-d507-4b91-9870-f51df186cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from galaxies_datasets import datasets\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, jaccard_score\n",
    "from keras import layers\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66404c6e-4755-4f44-b837-28bd2960d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FROM = 'local'\n",
    "NUM_EPOCHS = 7\n",
    "SIZE = 64  # Size of resized images and masks (in pixels). You may have to change batch sizes.\n",
    "\n",
    "MASK = 'spiral_mask'\n",
    "TRAIN_WITH = 'only'  # \"all\" uses all the images in the training dataset. \"only\" for spiraled galaxies only\n",
    "\n",
    "MIN_VOTE = 3  # this parameter defines the minimum amount of votes that the most voted pixel of a mask must have in order to be considered a spiral arm (barred) galaxy.\n",
    "\n",
    "THRESHOLD = 6  # threshold defines the minimum amount of votes that a pixel must have to be clasified as a spiral arm (bar).\n",
    "PATIENCE = 3   # You can choose to stop training after 'patience' amount of epochs without improvement in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dfe9dae-8748-459f-a5d1-898ccbb75d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (SIZE, SIZE), method=\"nearest\")\n",
    "    input_mask = tf.image.resize(input_mask, (SIZE, SIZE), method=\"nearest\")\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def augment(input_image, input_mask):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_up_down(input_image)\n",
    "        input_mask = tf.image.flip_up_down(input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def normalize(input_image):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "\n",
    "    return input_image\n",
    "\n",
    "\n",
    "def binary_mask(input_mask):\n",
    "    th = THRESHOLD\n",
    "    input_mask = tf.where(input_mask<th, tf.zeros_like(input_mask), tf.ones_like(input_mask))\n",
    "\n",
    "    return input_mask\n",
    "\n",
    "\n",
    "def load_image_train(datapoint):\n",
    "    input_image = datapoint['image']\n",
    "    input_mask = datapoint[MASK]\n",
    "    input_image, input_mask = resize(input_image, input_mask)\n",
    "    input_image, input_mask = augment(input_image, input_mask)\n",
    "    input_image = normalize(input_image)\n",
    "    input_mask = binary_mask(input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image_test(datapoint):\n",
    "    input_image = datapoint['image']\n",
    "    input_mask = datapoint[MASK]\n",
    "    input_image, input_mask = resize(input_image, input_mask)\n",
    "    input_image = normalize(input_image)\n",
    "    input_mask = binary_mask(input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "028f1ebd-b37a-42d7-92e0-71f32c520452",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('galaxy_zoo3d', split=['train[2:3420]', 'train[3666:6999]'], with_info=True)\n",
    "ds_train, ds_test = ds[0], ds[1]\n",
    "\n",
    "if TRAIN_WITH == 'all':\n",
    "    BUFFER_SIZE, BATCH_SIZE = 1000, 64\n",
    "    TRAIN_LENGTH, VAL_SIZE, TEST_SIZE = 22360, 4992, 2461\n",
    "elif TRAIN_WITH == 'only':\n",
    "    BUFFER_SIZE, BATCH_SIZE = 300, 16\n",
    "    if MASK == 'spiral_mask':\n",
    "        ds_train = ds_train.filter(lambda x: tf.reduce_max(x['spiral_mask']) >= MIN_VOTE)\n",
    "        ds_test = ds_test.filter(lambda x: tf.reduce_max(x['spiral_mask']) >= MIN_VOTE)\n",
    "        TRAIN_LENGTH, VAL_SIZE, TEST_SIZE = 4883, 1088, 551\n",
    "    elif MASK == 'bar_mask':\n",
    "        ds_train = ds_train.filter(lambda x: tf.reduce_max(x['bar_mask']) >= MIN_VOTE)\n",
    "        ds_test = ds_test.filter(lambda x: tf.reduce_max(x['bar_mask']) >= MIN_VOTE)\n",
    "        TRAIN_LENGTH, VAL_SIZE, TEST_SIZE = 3783, 832, 421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba58ce82-05d3-4505-968f-9ba1d849125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds_train.map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = ds_test.map(load_image_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_batches = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "validation_batches = test_dataset.take(VAL_SIZE).batch(BATCH_SIZE)\n",
    "test_batches = test_dataset.skip(VAL_SIZE).take(TEST_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41a1e16f-39db-4dc8-a283-229b46f4023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D(2)(f)\n",
    "    p = layers.Dropout(0.3)(p)\n",
    "\n",
    "    return f, p\n",
    "\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "\n",
    "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    x = layers.concatenate([x, conv_features])\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = double_conv_block(x, n_filters)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a92dd4e6-a3ad-418d-9655-ba4381460f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_model():\n",
    "\n",
    "    inputs = layers.Input(shape=(SIZE, SIZE, 3))\n",
    "\n",
    "    f1, p1 = downsample_block(inputs, SIZE / 2)\n",
    "    f2, p2 = downsample_block(p1, SIZE)\n",
    "    f3, p3 = downsample_block(p2, SIZE * 2)\n",
    "    f4, p4 = downsample_block(p3, SIZE * 4)\n",
    "\n",
    "    bottleneck = double_conv_block(p4, SIZE * 8)\n",
    "\n",
    "    u6 = upsample_block(bottleneck, f4, SIZE * 4)\n",
    "    u7 = upsample_block(u6, f3, SIZE * 2)\n",
    "    u8 = upsample_block(u7, f2, SIZE)\n",
    "    u9 = upsample_block(u8, f1, SIZE / 2)\n",
    "\n",
    "    outputs = layers.Conv2D(2, 1, padding=\"same\", activation=\"softmax\")(u9)\n",
    "\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24503131-14d3-4136-aac8-0f0719c03af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/jose/git-repos/imgalaxy/imgalaxy/resources/models'\n",
    "filename = 'poc'\n",
    "\n",
    "csv_log = CSVLogger(f'{path}{filename}/{filename}.csv', append=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=PATIENCE, mode='min')\n",
    "mcp_save_best = ModelCheckpoint(\n",
    "    filepath=f'{path}/{filename}/{filename}_best.h5', monitor='val_accuracy', mode='max', save_best_only=True\n",
    ")\n",
    "mcp_save_last = ModelCheckpoint(filepath=f'{path}{filename}/{filename}_last.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fbd5fe3-d4e4-4f15-a663-25ad076b96d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2135\n",
      "Epoch 1/7\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9876WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2607a0ae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2607a0ae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 251s 811ms/step - loss: 0.0626 - accuracy: 0.9876 - val_loss: 0.0485 - val_accuracy: 0.9873\n",
      "Epoch 2/7\n",
      "305/305 [==============================] - 244s 799ms/step - loss: 0.0213 - accuracy: 0.9918\n",
      "Epoch 3/7\n",
      "305/305 [==============================] - 229s 750ms/step - loss: 0.0087 - accuracy: 0.9965\n",
      "Epoch 4/7\n",
      "305/305 [==============================] - 231s 757ms/step - loss: 0.0041 - accuracy: 0.9983\n",
      "Epoch 5/7\n",
      "305/305 [==============================] - 246s 808ms/step - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 6/7\n",
      "305/305 [==============================] - 250s 820ms/step - loss: 6.2884e-04 - accuracy: 0.9998\n",
      "Epoch 7/7\n",
      "305/305 [==============================] - 246s 806ms/step - loss: 2.9617e-04 - accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "unet_model = build_unet_model()\n",
    "\n",
    "unet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "VAL_SUBSPLITS = 5\n",
    "TEST_LENGTH = VAL_SIZE + TEST_SIZE\n",
    "VALIDATION_STEPS = TEST_LENGTH // BATCH_SIZE // VAL_SUBSPLITS\n",
    "\n",
    "print(STEPS_PER_EPOCH * NUM_EPOCHS)\n",
    "model_history = unet_model.fit(\n",
    "    train_batches,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=validation_batches,\n",
    "    #callbacks=[csv_log, early_stop, mcp_save_best, mcp_save_last]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d80fa-a3dc-429a-b138-8d25a1ed67cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgalaxy-aEiF8FzA-py3.11",
   "language": "python",
   "name": "imgalaxy-aeif8fza-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
